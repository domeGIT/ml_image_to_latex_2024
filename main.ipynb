{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZYbFCS4LE-1",
        "outputId": "6d28da36-5ecd-4579-85a2-fd4edc75a9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deo koda potreban da bi u google colabu postojao pristup data folderu:\n",
        "# potrebno pokrenuti samo tokom prvog pokretanja koda u sesiji\n",
        "# pre toga je potrebno dostaviti data.tar na svoj google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dst = \"/content/data\"\n",
        "\n",
        "if os.path.exists(dst):\n",
        "     shutil.rmtree(dst)\n",
        "\n",
        "!cp /content/drive/MyDrive/data.tar /content/\n",
        "!tar -xf /content/data.tar -C /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAoL3BcYLPEP",
        "outputId": "a8cfcda8-a494-4f71-fe73-54b1a8baddc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"data\"\n",
        "\n",
        "RANDOM_STATE = 1219\n",
        "N_EPOCHS = 10\n",
        "BATCH_SIZE = 16 #a100\n",
        "LEARNING_RATE = 0.1\n",
        "WORKERS = 4"
      ],
      "metadata": {
        "id": "iBF2TzDULRWe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset klasa:"
      ],
      "metadata": {
        "id": "tLLbTdggLTLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class LatexDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Formiranje pytorch skupa podataka na osnovu csv fajla cije su kolone (ime_slike, string_latex_formule)\n",
        "\n",
        "    Nakon formiranja skupa, elementi su oblika (slika_u_obliku_tenzora, string_latex_formule)\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_path: str, transform=None):\n",
        "        \"\"\"\n",
        "        Ulazni argumenti:\n",
        "        csv_path (str): Put do CSV fajla csv fajla cije su kolone (ime_slike, string_latex_formule)\n",
        "        transform (callable, optional): Opcionalna transformacija koja se primenjuje na sve slike nakon formiranja skupa\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # promenimo kolonu image tako da ima ceo put do fajla\n",
        "        df['image'] = df.image.map(lambda x: os.path.join('/content/data/formula_images_processed', f'{x}'))\n",
        "        # formirajmo listu recnika (`self.walker`) gde su recnici redovi iz df\n",
        "        self.walker = df.to_dict('records')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.walker)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.walker[idx]\n",
        "\n",
        "        formula = item['formula']\n",
        "        image = torchvision.io.read_image(str(item['image']))\n",
        "        image = TF.rgb_to_grayscale(image, num_output_channels=1)  # (1, H, W)\n",
        "\n",
        "        return image, formula"
      ],
      "metadata": {
        "id": "dcriB01vLUHG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## text"
      ],
      "metadata": {
        "id": "6kxwd4zKLYTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from torch import Tensor\n",
        "\n",
        "class Text():\n",
        "    \"\"\"\n",
        "    Klasa koja enkapsulira bavljenje:\n",
        "    rečnikom, tokenizacijom, i konverzijom između celobrojnih identifikatora i odgovarajućeg stringa.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Inicijalizacija: učitavanje rečnika i podešavanje pravila za tokenizaciju\n",
        "        \"\"\"\n",
        "        # ručno podešavamo specijalne tokene\n",
        "        self.pad_id = 0\n",
        "        self.sos_id = 1\n",
        "        self.eos_id = 2\n",
        "\n",
        "        # objekti koji povezuju string token sa odgovarajućim celobrojnim id-jem\n",
        "        self.id2word = json.load(open(\"/content/data/vocab/100k_vocab.json\", \"r\")) # lista stringova\n",
        "        self.word2id = dict(zip(self.id2word, range(len(self.id2word)))) # mapa\n",
        "        # regularni izraz za razbijanje latex stringa u tokene\n",
        "        self.TOKENIZE_PATTERN = re.compile(\n",
        "            r\"(\\\\[a-zA-Z]+)|\"           # LaTeX komande poput \\frac, \\sqrt\n",
        "            r\"((\\\\)*[$-/:-?{-~!\\\"^_`\\[\\]])|\"  # matematički simboli\n",
        "            r\"(\\w)|\"                    # izolovana slova i brojevi\n",
        "            r\"(\\\\)\"                     # pojedinačne `\\`\n",
        "            )\n",
        "        # broj tokena\n",
        "        self.n_class = len(self.id2word)\n",
        "\n",
        "    def int2text(self, x: Tensor):\n",
        "        \"\"\"\n",
        "        Argumenti:\n",
        "            x (Tensor): 1D tenzor token ID-jeva.\n",
        "        Povratna vrednost:\n",
        "            str: String tokena razmaknutih razmakom, bez specijalnih (eos, sos, pad) tokena.\n",
        "        \"\"\"\n",
        "        return \" \".join([self.id2word[i] for i in x if i > self.eos_id])\n",
        "\n",
        "    def text2int(self, formula: str):\n",
        "        \"\"\"\n",
        "        Argumenti:\n",
        "            formula (string): LaTeX formula u svom string obliku\n",
        "        Povratna vrednost:\n",
        "            Tensor: 1D tenzor token ID-jeva\n",
        "        \"\"\"\n",
        "        return torch.LongTensor([self.word2id[i] for i in self.tokenize(formula)])\n",
        "\n",
        "    def tokenize(self, formula: str):\n",
        "        \"\"\"\n",
        "        Argumenti:\n",
        "            formula (str): LaTeX formula u svom string obliku\n",
        "        Povratna vrednost:\n",
        "            list[str]: Lista tokena (znači lista stringova) koji odgovaraju formuli\n",
        "        \"\"\"\n",
        "        tokens = re.finditer(self.TOKENIZE_PATTERN, formula)\n",
        "        tokens = list(map(lambda x: x.group(0), tokens))\n",
        "        tokens = [x for x in tokens if x is not None and x != \"\"]\n",
        "        return tokens"
      ],
      "metadata": {
        "id": "_z96Nci6LZnt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## collate\n",
        "\n",
        "Funkcija koju koristi PyTorch-ev DataLoader, pri kombinovanju liste pojedinačnih uzoraka iz skupa u jedan batch.\n",
        "\n",
        "Podrazumevana Torcheva akcija za ovo je da samo stekuje uzorke. Kako su u našem skupu formule promenljivih dužina, bilo je potrebno da napišemo posebnu collate funkciju sa odgovarajućim pad-ovanjem."
      ],
      "metadata": {
        "id": "LUS_34_bLbmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "text = Text()\n",
        "\n",
        "def collate_fn(batch, text):\n",
        "    \"\"\"\n",
        "    Posebna collate funkcija za batchovanje parova (slika, LaTeX), formirana za PyTorch DataLoader.\n",
        "    Custom collate function for batching image–LaTeX formula pairs.\n",
        "\n",
        "    1. Transformiše LaTeX formula string u sekvencu token ID-jeva (pomoću Text klase)\n",
        "    2. Računa dužine svih sekvenci\n",
        "    3. Pad-uje sekvence na dužinu najduže u batchu i dodaje sos i eos tokene\n",
        "    4. Pad-uje slike na istu širinu i visinu\n",
        "    5. Ovako modifikovane slike i formule stekuje u tenzore spremne za model\n",
        "\n",
        "    Argumenti:\n",
        "        batch (list[tuple]): Lista uzoraka iz dataseta. Jedan uzorak = `(image, formula_string)`\n",
        "        text (Text): Instanca klase `Text`\n",
        "\n",
        "    Povratna vrednost:\n",
        "        torka:\n",
        "            - images (Tensor): Float tenzor oblika `(BATCH_SIZE, CHANNELS, H, W)`\n",
        "            koji sadrži ped-ovane slike\n",
        "            - formulas (Tensor): Long tenzor oblika `(BATCH_SIZE, L)`\n",
        "            koji sadrži ped-ovane sekvence token ID-jeva, uključujući sos i eos\n",
        "            - formula_len (Tensor): Long tenzor oblika `(B,)`\n",
        "            koji sadrži originalne dužine sekvenci formula - pre ped-ovanja, bez eos\n",
        "    \"\"\"\n",
        "\n",
        "    formulas = [text.text2int(str(i[1])) for i in batch]\n",
        "    formula_len = torch.tensor([len(f) + 1 for f in formulas], dtype=torch.long)\n",
        "    formulas = pad_sequence(formulas, batch_first=True)\n",
        "\n",
        "    batch_size = len(batch)\n",
        "    sos = torch.full((batch_size, 1), text.sos_id, dtype=torch.long)\n",
        "    eos = torch.full((batch_size, 1), text.eos_id, dtype=torch.long)\n",
        "    formulas = torch.cat((sos, formulas, eos), dim=-1)\n",
        "\n",
        "\n",
        "    images = [i[0] for i in batch]\n",
        "    max_width, max_height = 0, 0\n",
        "    for img in images:\n",
        "        c, h, w = img.size()\n",
        "        max_width = max(max_width, w)\n",
        "        max_height = max(max_height, h)\n",
        "\n",
        "    def pad_image(img):\n",
        "        c, h, w = img.size()\n",
        "        padding = (0, 0, max_width - w, max_height - h)\n",
        "        return torchvision.transforms.functional.pad(img, padding, fill=0)\n",
        "\n",
        "    images = [pad_image(img) for img in images]\n",
        "    images = torch.stack(images).to(dtype=torch.float)\n",
        "\n",
        "    return images, formulas, formula_len\n"
      ],
      "metadata": {
        "id": "JoRBFD4TLc3F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enkoder"
      ],
      "metadata": {
        "id": "8SgaFiAMLf2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Konvolucioni enkoder za ekstrakovanje reprezentacija atributa crno-belih slika\n",
        "\n",
        "    Konvolucioni slojevi, ReLU aktivacije i max-pooling, potom flattening.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder_dim: int):\n",
        "        super().__init__()\n",
        "        # enkoder atributa\n",
        "        self.feature_encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1),    # Conv 1\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),           # downsample\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),  # Conv 2\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),           # downsample\n",
        "\n",
        "            nn.Conv2d(128, encoder_dim, 3, 1, 1),  # Conv 3\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # dimenzionalnost autput vektora atributa\n",
        "        self.encoder_dim = encoder_dim\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass konvolucionog enkodera. Input mora biti crno-bela slika.\n",
        "\n",
        "        Argumenti:\n",
        "            x (Tensor): ulazni tenzor oblika (batch_size, channels=1, width, height)\n",
        "\n",
        "        Povratna vrednost:\n",
        "            Tensor: Enkodirani tenzor atributa, oblika (batch_size, seq_len, encoder_dim)\n",
        "            gde seq_len = w * h  (w i h su širina i visina slike nakon konvolucija i poolinga)\n",
        "            encoder_dim je broj autput kanala u poslednjem konvolucionom sloju\n",
        "        \"\"\"\n",
        "        encoder_out = self.feature_encoder(x)        # (bs, c, w, h)\n",
        "        encoder_out = encoder_out.permute(0, 2, 3, 1) # (bs, w, h, c)\n",
        "        bs, w, h, d = encoder_out.size()\n",
        "        encoder_out = encoder_out.view(bs, -1, d)   # flatten spatial dims\n",
        "        return encoder_out"
      ],
      "metadata": {
        "id": "beRP4SHjLj3N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# attention"
      ],
      "metadata": {
        "id": "F0q5_jCwLlwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enoder_dim: int = 512, decoder_dim: int = 512, attention_dim: int = 512):\n",
        "        super().__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        Racunamo kontekst vektor na osnovu sledecih jednacina\n",
        "        e = tanh((Wₕhₜ₋₁ + bₕ) + (WᵥV + bᵥ))\n",
        "        αₜ = Softmax(Wₐ·e + bₐ)\n",
        "        cₜ = ∑ᵢ αₜⁱ vᵢ, where vᵢ ∈ V\n",
        "        \"\"\"\n",
        "        self.decoder_attention = nn.Linear(decoder_dim, attention_dim, bias=False) # W_h * h_{t-1}\n",
        "        self.encoder_attention = nn.Linear(enoder_dim, attention_dim, bias=False) # W_V * V\n",
        "        self.attention = nn.Linear(attention_dim, 1, bias=False)      # W_a * attn\n",
        "\n",
        "        # Softmax će pretvoriti sirove rezultate u raspodelu verovatnoće (težine pažnje).\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, h: Tensor, V: Tensor):\n",
        "        \"\"\"\n",
        "        Izračunaj kontekst vektor tako što pažljivo posmatraš najrelevantnije delove slike.\n",
        "\n",
        "        Argumenti:\n",
        "            h: Prethodno skriveno stanje LSTM dekodera. Oblik: (batch_size, decoder_dim)\n",
        "            V: Mapa karakteristika. Oblik: (batch_size, w * h, encoder_dim)\n",
        "\n",
        "        Povratna vrednost:\n",
        "            context (Tensor): Vektor koji iz mapa karakteristike izvlaci relevantne podatke za generisanje sledeceg karaktera.\n",
        "                            Oblik: (batch_size, decoder_dime)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        attn_1 = self.decoder_attention(h) #(b, decoder_dim) -> (b, attention_dim)\n",
        "        attn_2 = self.encoder_attention(V) #(b, w*h, enoder_dim) -> (b, w*h, attention_dim)\n",
        "\n",
        "        attention= self.attention(torch.tanh(attn_1.unsqueeze(1) + attn_2)).squeeze(2)\n",
        "        # attn_1.unsqueeze(1): (b, 1, attention_dim)\n",
        "        # attn_2: (b, w*h, attention_dim)\n",
        "        # tanh(): (b, w*h, attention_dim)\n",
        "        # attention: (b, w*h, 1) -> squeeze(2) -> (b, w*h)\n",
        "\n",
        "        alpha = self.softmax(attention)\n",
        "\n",
        "\n",
        "        context = (alpha.unsqueeze(2) * V).sum(dim=1)\n",
        "        # alpha.unsqueeze(2): (b, w*h, 1)\n",
        "        # V: (b, w*h, enoder_dim)\n",
        "        # product: (b, w*h, enoder_dim)\n",
        "        # context: (b, enoder_dim)\n",
        "        return context"
      ],
      "metadata": {
        "id": "H-MgvZmtLn40"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dekoder"
      ],
      "metadata": {
        "id": "S8drV_YbLpkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,n_class: int,embedding_dim: int = 80,encoder_dim: int = 512,decoder_dim: int = 512,attention_dim: int = 512,\n",
        "        num_layers: int = 1,dropout: float = 0.1,bidirectional: bool = False,sos_id: int = 1,eos_id: int = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        Implementacija dekodera za Image-to-Latex model.\n",
        "        Koristi LSTM ćeliju i Luong pažnju da generiše LaTeX simbole korak po korak.\n",
        "        cₜ = Attention(hₜ₋₁, V)\n",
        "        eₜ = Embedding(yₜ)\n",
        "        (oₜ, hₜ) = LSTM(hₜ₋₁, [cₜ, eₜ])\n",
        "        p(yₜ₊₁ | y₁, ..., yₜ) = Softmax(Wₒ · oₜ + bₒ)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.sos_id = sos_id\n",
        "        self.eos_id = eos_id\n",
        "\n",
        "        # Embedding layer konvertuje token ID u vektor\n",
        "        self.embedding = nn.Embedding(n_class, embedding_dim)  # (vocab_size, embedding_dim)\n",
        "\n",
        "        # Instanca mehanizma pažnje\n",
        "        self.attention = Attention(encoder_dim, decoder_dim, attention_dim)  # Veličina enkodera -> veličina pažnje\n",
        "\n",
        "        # Linearni sloj za spajanje embeddinga i konteksta pažnje\n",
        "        self.concat = nn.Linear(embedding_dim + encoder_dim, decoder_dim)  # (embedding_dim + encoder_dim) -> decoder_dim\n",
        "\n",
        "        # Prvi LSTM sloj\n",
        "        self.rnn = nn.LSTM(\n",
        "            decoder_dim,\n",
        "            decoder_dim,\n",
        "            num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "        # Dropout za regularizaciju\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Drugi LSTM sloj za dublji model\n",
        "        self.rnn2 = nn.LSTM(\n",
        "            decoder_dim,\n",
        "            decoder_dim,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "        # Izlazni sloj koji preslikuje u prostor rečnika\n",
        "        self.out = nn.Linear(decoder_dim, n_class)  # (decoder_dim) -> (n_class)\n",
        "\n",
        "        # LogSoftmax za stabilnost prilikom računanja gubitka\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "        # Inicijalizacija težina\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, layer):\n",
        "        if isinstance(layer, nn.Embedding):\n",
        "            nn.init.orthogonal_(layer.weight)\n",
        "        elif isinstance(layer, nn.LSTM):\n",
        "            for name, param in self.rnn.named_parameters():\n",
        "                if name.startswith(\"weight\"):\n",
        "                    nn.init.orthogonal_(param)\n",
        "\n",
        "    def forward(self, y, encoder_out=None, hidden_state=None):\n",
        "        \"\"\"\n",
        "        Generiše sledeći token na osnovu trenutnog stanja i izlaza enkodera.\n",
        "\n",
        "        Argumenti:\n",
        "            y: Ulazni tokeni. Oblik: (batch_size, target_len)\n",
        "            encoder_out: Izlaz enkodera (V). Oblik: (batch_size, encoder_dim, w', h')\n",
        "            hidden_state: Prethodno skriveno stanje (h, c). Oblik: (num_layers * num_directions, batch_size, decoder_dim)\n",
        "\n",
        "        Povratna vrednost:\n",
        "            out: Log-verovatnoće za sledeći token. Oblik: (batch_size, 1, n_class)\n",
        "            hidden_state: Ažurirano skriveno stanje.\n",
        "        \"\"\"\n",
        "\n",
        "        h, c = hidden_state  # (b, decoder_dim), (b, decoder_dim)\n",
        "\n",
        "        embed = self.embedding(y)  # (b, seq_len, embedding_dim)\n",
        "        attention_context = self.attention(h, encoder_out)  # (b, encoder_dim)\n",
        "\n",
        "        rnn_input = torch.cat([embed[:, -1], attention_context], dim=1)  # (b, embedding_dim + encoder_dim)\n",
        "        rnn_input = self.concat(rnn_input)  # (b, decoder_dim)\n",
        "\n",
        "        rnn_input = rnn_input.unsqueeze(1)  # (b, 1, decoder_dim)\n",
        "        hidden_state = (h.unsqueeze(0), c.unsqueeze(0))  # (1, b, decoder_dim), (1, b, decoder_dim)\n",
        "\n",
        "        out, hidden_state = self.rnn(rnn_input, hidden_state)  # out: (b, 1, decoder_dim)\n",
        "\n",
        "        out = self.dropout(out)  # (b, 1, decoder_dim)\n",
        "\n",
        "        out, hidden_state = self.rnn2(out, hidden_state)  # out: (b, 1, decoder_dim)\n",
        "        out = self.logsoftmax(self.out(out))  # (b, 1, n_class)\n",
        "\n",
        "        h, c = hidden_state\n",
        "        return out, (h.squeeze(0), c.squeeze(0))  # Squeeze dimenziju slojeva"
      ],
      "metadata": {
        "id": "0uTEHNSOLqQM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "Qo5XqhNlLskL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Image2LatexModel(nn.Module):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,n_class: int,embedding_dim: int = 80,encoder_dim: int = 512,decoder_dim: int = 512,attention_dim: int = 512,\n",
        "        num_layers: int = 1,dropout: float = 0.1,bidirectional: bool = False,text: Text = None, beam_width: int = 5, sos_id: int = 1,eos_id: int = 2, decode_type: str = \"greedy\"):\n",
        "        super().__init__()\n",
        "        self.encoder = ConvEncoder(encoder_dim=encoder_dim)\n",
        "        self.decoder = Decoder(n_class=n_class,embedding_dim=embedding_dim,encoder_dim=encoder_dim,decoder_dim=decoder_dim,attention_dim=attention_dim,num_layers=num_layers,dropout=dropout,bidirectional=bidirectional,sos_id=sos_id,eos_id=eos_id)\n",
        "\n",
        "        self.init_h = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.init_c = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.n_class = n_class\n",
        "        self.decode_type = decode_type\n",
        "        self.text = text\n",
        "        self.beam_width = beam_width\n",
        "        self.encoder = ConvEncoder(encoder_dim=encoder_dim)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # TODO: why do we init the hidden state like this and not just 0?\n",
        "    def init_decoder_hidden_state(self, V: Tensor):\n",
        "        \"\"\"\n",
        "        Inicijalizuje skriveno stanje dekodera na osnovu autputa enkodera\n",
        "        Argumenti:\n",
        "            V (Tensor): autput enkodera, oblika (batch_size, seq_len=w*h, encoder_dim).\n",
        "        Povratna vrednost:\n",
        "            (h, c): Dvojka tenzora, oba oblika (batch_size, decoder_dim),\n",
        "            koji predstavljaju inicijalno skriveno i stanje ćelije za dekoder.\n",
        "        \"\"\"\n",
        "        encoder_mean = V.mean(dim=1)\n",
        "        h = torch.tanh(self.init_h(encoder_mean))\n",
        "        c = torch.tanh(self.init_c(encoder_mean))\n",
        "        return h, c\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor, y_len: Tensor):\n",
        "        \"\"\"\n",
        "        Propagacija unapred\n",
        "        Argumenti:\n",
        "            x (Tensor): Ulazna slika kao tenzor oblika (batch_size, channels, H, W).\n",
        "            y (Tensor): Vrednosti ID-jeva koji odgovaraju stvarnim tokena,\n",
        "            tenzor oblika (batch_size, seq_len).\n",
        "            y_len (Tensor): Dužine stvarnih sekvenci pre pad-ovanja,\n",
        "            tenzor oblika (batch_size,).\n",
        "\n",
        "        Povratna vrednost:\n",
        "            Tensor: Logiti za poczicije tokena,\n",
        "            tenzor oblika (batch_size, seq_len, vocab_size),\n",
        "        \"\"\"\n",
        "        encoder_out = self.encoder(x)\n",
        "\n",
        "        hidden_state = self.init_decoder_hidden_state(encoder_out)\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for t in range(y_len.max().item()):\n",
        "            dec_input = y[:, t].unsqueeze(1)\n",
        "            out, hidden_state = self.decoder(dec_input, encoder_out, hidden_state)\n",
        "            predictions.append(out.squeeze(1))\n",
        "\n",
        "        predictions = torch.stack(predictions, dim=1)\n",
        "        return predictions\n",
        "\n",
        "    def decode_greedy(self, x: Tensor, max_length: int = 150):\n",
        "        \"\"\"\n",
        "        Greedy dekoding: odabrati najverovatniji token u svakom koraku.\n",
        "\n",
        "        Argumenti:\n",
        "            x (Tensor): Ulazna slika kao tenzor oblika (batch_size, channels, H, W).\n",
        "            max_length (int, optional): max dužina povrstne liste predviđenih\n",
        "                ID-jeva tokena. Podrazumevano: 150.\n",
        "\n",
        "        Povratna vrednost:\n",
        "            List[int]: Sekvenca predviđenih ID-jeva tokena (dužine <= max_length).\n",
        "        \"\"\"\n",
        "        encoder_out = self.encoder(x)\n",
        "        bs = encoder_out.size(0)\n",
        "        device = encoder_out.device\n",
        "\n",
        "        hidden_state = self.init_decoder_hidden_state(encoder_out)\n",
        "\n",
        "        y = torch.tensor([self.decoder.sos_id], device=device).view(bs, -1)\n",
        "\n",
        "        predictions = []\n",
        "        for t in range(max_length):\n",
        "            out, hidden_state = self.decoder(y, encoder_out, hidden_state)\n",
        "\n",
        "            k = out.argmax().item()\n",
        "            predictions.append(k)\n",
        "\n",
        "            y = torch.tensor([k], device=device).view(bs, -1)\n",
        "        return predictions\n",
        "\n",
        "    def decode_beam_search(self, x, max_length=150):\n",
        "      \"\"\"\n",
        "      Dekodiranje pomoću beam search-a: u svakom koraku čuva najboljih k kandidata za sekvence.\n",
        "\n",
        "      Argumenti:\n",
        "            x (Tensor):Ulazna slika kao tenzor oblika (1, channels, H, W)\n",
        "                        #!!TODO: obezbediti batch dekodiranje, da x može da bude oblika\n",
        "                        (batch_size, channels, H, W)\n",
        "            max_length (int, optional): max dužina povrstne liste predviđenih\n",
        "                ID-jeva tokena. Podrazumevano: 150.\n",
        "\n",
        "        Returns:\n",
        "            List[int]:  Sekvenca predviđenih ID-jeva tokena, sa najvećim beam skorom\n",
        "      \"\"\"\n",
        "      encoder_out = self.encoder(x)\n",
        "      bs = encoder_out.size(0)  # 1\n",
        "\n",
        "      hidden_state = self.init_decoder_hidden_state(encoder_out)\n",
        "\n",
        "      list_candidate = [\n",
        "          ([self.decoder.sos_id], hidden_state, 0)\n",
        "      ]  # (input, hidden_state, log_prob)\n",
        "      for t in range(max_length):\n",
        "          new_candidates = []\n",
        "          for inp, state, log_prob in list_candidate:\n",
        "              y = torch.LongTensor([inp[-1]]).view(bs, -1).to(device=x.device)\n",
        "              out, hidden_state = self.decoder(y, encoder_out, state)\n",
        "\n",
        "              topk = out.topk(self.beam_width)\n",
        "              new_log_prob = topk.values.view(-1).tolist()\n",
        "              new_idx = topk.indices.view(-1).tolist()\n",
        "              for val, idx in zip(new_log_prob, new_idx):\n",
        "                  new_inp = inp + [idx]\n",
        "                  new_candidates.append((new_inp, hidden_state, log_prob + val))\n",
        "\n",
        "          new_candidates = sorted(new_candidates, key=lambda x: x[2], reverse=True)\n",
        "          list_candidate = new_candidates[: self.beam_width]\n",
        "\n",
        "      return list_candidate[0][0]\n",
        "\n",
        "    def decode_greedy_batch(self, x: Tensor, max_length: int = 150):\n",
        "\n",
        "        encoder_out = self.encoder(x)\n",
        "        bs = encoder_out.size(0)\n",
        "        device = encoder_out.device\n",
        "\n",
        "        hidden_state = self.init_decoder_hidden_state(encoder_out)\n",
        "\n",
        "        y = torch.full((bs, 1), self.decoder.sos_id, dtype=torch.long, device=device)\n",
        "\n",
        "        sequences = [[self.decoder.sos_id] for _ in range(bs)]  # store sequences per image\n",
        "        finished = [False] * bs\n",
        "\n",
        "        for t in range(max_length):\n",
        "            out, hidden_state = self.decoder(y, encoder_out, hidden_state)\n",
        "            preds = out.argmax(dim=-1) # (batch_size, 1)\n",
        "\n",
        "            for i in range(bs):\n",
        "                if not finished[i]:\n",
        "                    token_id = preds[i].item()\n",
        "                    sequences[i].append(token_id)\n",
        "                    if token_id == self.decoder.eos_id:\n",
        "                        finished[i] = True\n",
        "\n",
        "            y = preds  # next input\n",
        "\n",
        "            if all(finished):\n",
        "                break\n",
        "        return sequences\n",
        "\n",
        "    def decode(self, x: Tensor, max_length: int = 150):\n",
        "        \"\"\"\n",
        "        Decode funkcija, u zavisnosti od `self.decode_type` podržava\n",
        "        greedy ili beam search enkoding.\n",
        "        \"\"\"\n",
        "        if self.decode_type == \"greedy\":\n",
        "            predict = self.decode_greedy(x, max_length)\n",
        "        elif self.decode_type == \"beamsearch\":\n",
        "            predict = self.decode_beam_search(x, max_length)\n",
        "        return predict\n",
        "\n",
        "    def compute_loss(self, outputs, formulas_out):\n",
        "        \"\"\"\n",
        "        Funkcija računa cross entropy loss između predviđanja modela i stvarnih vrednosti.\n",
        "\n",
        "        Argumenti:\n",
        "            outputs (Tensor): Predviđanja modela, tenzor oblika\n",
        "                (batch_size, seq_len, vocab_size).\n",
        "            formulas_out (Tensor): Stvarna vrednost ID-jeva tokena, oblika\n",
        "                (batch_size, seq_len).\n",
        "\n",
        "        Povratna vrednost:\n",
        "            Tensor: Skalarna povratna vrednost loss funkcije.\n",
        "        \"\"\"\n",
        "        bs, t, _ = outputs.size()\n",
        "        return self.criterion(\n",
        "            outputs.reshape(bs * t, -1),   # flatten predictions\n",
        "            formulas_out.reshape(-1)       # flatten targets\n",
        "        )"
      ],
      "metadata": {
        "id": "lmG9T6W8Luac"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# Dodatna funkcija transformacije slika,\n",
        "# smanjuje slike (čuva proporcije)\n",
        "# radi ubrzavanja izvršavanja treniranja\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "4JuQYwPwLwG8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def exact_match(pred_list, truth_list):\n",
        "    \"\"\"\n",
        "    Računa EM skor između predviđenih i stvarnih vrednosti sekvenci.\n",
        "\n",
        "    Argumenti:\n",
        "        pred_list (List[List[str]]): batch predviđenih sekvenci tokena\n",
        "        truth_list (List[List[str]]): batch stvarnih sekvenci tokena\n",
        "\n",
        "    Povratna vrednost:\n",
        "        Tensor: skalarni tenzor koji sadrži srednju vrednost EM skorova u batchu.\n",
        "        vrednosti EM skorova u batchu su:\n",
        "            - 1, ako su predviđena i stvarna sekvenca identične\n",
        "            - 0, inače\n",
        "    \"\"\"\n",
        "    em_scores = []\n",
        "    for pred, truth in zip(pred_list, truth_list):\n",
        "        len_pred = len(pred)\n",
        "        len_truth = len(truth)\n",
        "        max_len = max(len_pred, len_truth)\n",
        "\n",
        "        # Pad both sequences to the same length\n",
        "        padded_pred = pred + [\"\"] * (max_len - len_pred)\n",
        "        padded_truth = truth + [\"\"] * (max_len - len_truth)\n",
        "\n",
        "        # Calculate EM for this single pair\n",
        "        em = (np.array(padded_pred) == np.array(padded_truth)).all()\n",
        "        em_scores.append(em)\n",
        "\n",
        "    # Return the mean EM score for the entire batch\n",
        "    return torch.tensor(np.mean(em_scores))"
      ],
      "metadata": {
        "id": "45eRe7DQLxYz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# za logovanje metrika modela:\n",
        "\n",
        "import json\n",
        "\n",
        "os.makedirs(\"/content/drive/My Drive/im2latex/\", exist_ok=True)\n",
        "\n",
        "log_file = \"/content/drive/My Drive/im2latex/training_log.jsonl\""
      ],
      "metadata": {
        "id": "4NOvAO-xszNU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import random\n",
        "MAX_LENGTH=150\n",
        "EFFECTIVE_BATCH_SIZE = 64\n",
        "\n",
        "def get_device():\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def bind_gpu(data):\n",
        "    device = get_device()\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [bind_gpu(data_elem) for data_elem in data]\n",
        "    else:\n",
        "        return data.to(device, non_blocking=True)\n",
        "\n",
        "# Priprema podataka\n",
        "text_processor = Text()\n",
        "\n",
        "#plz ucitaj ih\n",
        "train_dataset = LatexDataset('/content/data/im2latex_train.csv', transform=transform)\n",
        "val_dataset = LatexDataset('/content/data/im2latex_validate.csv', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,  # important for training\n",
        "    num_workers=WORKERS,\n",
        "    collate_fn=lambda batch: collate_fn(batch, text)\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,  # usually keep validation deterministic\n",
        "    num_workers=WORKERS,\n",
        "    collate_fn=lambda batch: collate_fn(batch, text)\n",
        ")\n",
        "\n",
        "# Inicijalizacija modela,greske,scheduler,optimizera\n",
        "device = get_device()\n",
        "\n",
        "model = Image2LatexModel(\n",
        "    n_class=text_processor.n_class,\n",
        "    text=text_processor,\n",
        "    beam_width=5,\n",
        "    sos_id=text_processor.sos_id,\n",
        "    eos_id=text_processor.eos_id\n",
        ").to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002, betas=(0.9, 0.98))\n",
        "\n",
        "total_steps = (len(train_dataset) // EFFECTIVE_BATCH_SIZE) * N_EPOCHS\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, total_steps=total_steps)\n",
        "accumulation_steps = EFFECTIVE_BATCH_SIZE // BATCH_SIZE\n",
        "\n",
        "scaler = GradScaler()\n",
        "#treninng\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "        images, formulas, formula_len = bind_gpu(batch)\n",
        "\n",
        "        formulas_in = formulas[:, :-1]\n",
        "        formulas_out = formulas[:, 1:]\n",
        "\n",
        "        with autocast():\n",
        "          outputs = model(images, formulas_in, formula_len)\n",
        "\n",
        "          loss = criterion(outputs.reshape(-1, outputs.shape[-1]), formulas_out.reshape(-1))\n",
        "          loss = loss / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        train_loss += loss.item() * accumulation_steps\n",
        "\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "        del images, formulas, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    if (batch_idx + 1) % accumulation_steps != 0:\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} - Average Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # model save\n",
        "    os.makedirs(\"/content/drive/My Drive/im2latex/saved_models\", exist_ok=True)\n",
        "    path = f\"/content/drive/My Drive/im2latex/saved_models/model{epoch+1}.pt\"\n",
        "    torch.save(model, path)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_bleu = 0.0\n",
        "    val_em = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        i = 0\n",
        "        for batch in val_loader:\n",
        "\n",
        "            images, formulas, formula_len = bind_gpu(batch)\n",
        "            formulas_in = formulas[:, :-1]\n",
        "            formulas_out = formulas[:, 1:]\n",
        "\n",
        "            with autocast():\n",
        "              outputs = model(images, formulas_in, formula_len)\n",
        "              loss = criterion(outputs.reshape(-1, outputs.shape[-1]), formulas_out.reshape(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            \"\"\" ovo je 1 po 1 decoding varijanta:\n",
        "            predicts = []\n",
        "            truths = []\n",
        "            for img, formula in zip(images, formulas):\n",
        "                pred_tokens = model.decode(img.unsqueeze(0), max_length=MAX_LENGTH)\n",
        "                truth_tokens = formula.tolist()\n",
        "\n",
        "                predicts.append(pred_tokens)\n",
        "                truths.append(truth_tokens)\n",
        "            \"\"\"\n",
        "            \"\"\"batch decoding varijanta:\"\"\"\n",
        "            predicts = model.decode_greedy_batch(images, max_length=MAX_LENGTH)\n",
        "            truths = [formula.tolist() for formula in formulas]\n",
        "\n",
        "            predict_strings = [text_processor.tokenize(text_processor.int2text(p)) for p in predicts]\n",
        "            truth_strings = [text_processor.tokenize(text_processor.int2text(t)) for t in truths]\n",
        "\n",
        "            bleu4 = corpus_bleu([[t] for t in truth_strings], predict_strings)\n",
        "            em = exact_match(predict_strings, truth_strings)\n",
        "\n",
        "            val_bleu += bleu4\n",
        "            val_em += em\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    avg_val_bleu = val_bleu / len(val_loader)\n",
        "    avg_val_em = val_em / len(val_loader)\n",
        "\n",
        "    epoch_metrics = {\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": float(avg_train_loss),\n",
        "        \"val_loss\": float(avg_val_loss),\n",
        "        \"bleu4\": float(avg_val_bleu),\n",
        "        \"em\": float(avg_val_em)\n",
        "    }\n",
        "\n",
        "    # Append as a single line\n",
        "    with open(log_file, \"a\") as file:\n",
        "        file.write(json.dumps(epoch_metrics) + \"\\n\")\n",
        "\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}, BLEU4: {avg_val_bleu:.4f}, EM: {avg_val_em:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "torch.save(model.state_dict(), 'image2latex_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03d4zNpKLzFj",
        "outputId": "b6a187e6-10af-4e5a-9fc4-b1e9c279bba1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3096860714.py:60: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-3096860714.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Average Train Loss: 2.6621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3096860714.py:121: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.8729, BLEU4: 0.0339, EM: 0.0000\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Average Train Loss: 1.6273\n",
            "Validation Loss: 1.4634, BLEU4: 0.0770, EM: 0.0000\n",
            "Epoch 3/10\n",
            "Epoch 3 - Average Train Loss: 1.3884\n",
            "Validation Loss: 1.3084, BLEU4: 0.1191, EM: 0.0000\n",
            "Epoch 4/10\n",
            "Epoch 4 - Average Train Loss: 1.2596\n",
            "Validation Loss: 1.2170, BLEU4: 0.1440, EM: 0.0000\n",
            "Epoch 5/10\n",
            "Epoch 5 - Average Train Loss: 1.1618\n",
            "Validation Loss: 1.1436, BLEU4: 0.1626, EM: 0.0000\n",
            "Epoch 6/10\n",
            "Epoch 6 - Average Train Loss: 1.0725\n",
            "Validation Loss: 1.0707, BLEU4: 0.1921, EM: 0.0000\n",
            "Epoch 7/10\n",
            "Epoch 7 - Average Train Loss: 0.9907\n",
            "Validation Loss: 1.0212, BLEU4: 0.2114, EM: 0.0002\n",
            "Epoch 8/10\n",
            "Epoch 8 - Average Train Loss: 0.9181\n",
            "Validation Loss: 0.9825, BLEU4: 0.2343, EM: 0.0000\n",
            "Epoch 9/10\n",
            "Epoch 9 - Average Train Loss: 0.8660\n",
            "Validation Loss: 0.9665, BLEU4: 0.2489, EM: 0.0002\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Tried to step 7421 times. The specified number of total steps is 7420",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3096860714.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformulas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_DEPRECATION_WARNING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mget_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_num\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2132\u001b[0m                 \u001b[0;34mf\"Tried to step {step_num} times. The specified number of total steps is {self.total_steps}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Tried to step 7421 times. The specified number of total steps is 7420"
          ]
        }
      ]
    }
  ]
}