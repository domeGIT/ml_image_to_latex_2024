{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d453c4f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d453c4f9",
        "outputId": "f7836d33-55ba-4c6d-d335-54d67cea9650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ml_image_to_latex_2024' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/domeGIT/ml_image_to_latex_2024"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhNYMt4cYGzV",
        "outputId": "c7e8b9da-05d9-492e-a64d-2f2f72542d43"
      },
      "id": "PhNYMt4cYGzV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import shutil # potrebno za google colab\n",
        "\n",
        "from ml_image_to_latex_2024.image2latex import Text, LatexDataset, Image2LatexModel, exact_match, collate_fn, get_device, bind_gpu\n",
        "from ml_image_to_latex_2024.image2latex import ConvEncoder, Decoder, Attention"
      ],
      "metadata": {
        "id": "l3hMf6PFYK5e"
      },
      "id": "l3hMf6PFYK5e",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raspakivanje data.tar u /content/data.tar\n",
        "dst = \"/content/data\"\n",
        "\n",
        "if os.path.exists(dst):\n",
        "     shutil.rmtree(dst)\n",
        "\n",
        "!cp /content/ml_image_to_latex_2024/data.tar /content/\n",
        "!tar -xf /content/data.tar -C /content"
      ],
      "metadata": {
        "id": "fHtARNS8gIEF"
      },
      "id": "fHtARNS8gIEF",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Priprema log fajla za čuvanje rezultata tessta"
      ],
      "metadata": {
        "id": "LdN5O5L1hgpu"
      },
      "id": "LdN5O5L1hgpu"
    },
    {
      "cell_type": "code",
      "source": [
        "# MOUNTOVANJE DRAJVA\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIA4FQ3KhTGs",
        "outputId": "f2550afb-952a-4e2c-e8ef-17d3a97e7e76"
      },
      "id": "WIA4FQ3KhTGs",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uvođenje log fajla\n",
        "os.makedirs(\"/content/drive/My Drive/im2latex/\", exist_ok=True)\n",
        "\n",
        "log_file = \"/content/drive/My Drive/im2latex/test_log.json\""
      ],
      "metadata": {
        "id": "GUvPMRUQezSP"
      },
      "id": "GUvPMRUQezSP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uvođenje objekata i definisanje parametara potrebnih za test"
      ],
      "metadata": {
        "id": "tSz4-wDvh488"
      },
      "id": "tSz4-wDvh488"
    },
    {
      "cell_type": "code",
      "source": [
        "# konfig/parametri\n",
        "BATCH_SIZE = 16\n",
        "WORKERS = 4\n",
        "MAX_LENGTH = 150"
      ],
      "metadata": {
        "id": "SyhDByEUcLqE"
      },
      "id": "SyhDByEUcLqE",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_device()"
      ],
      "metadata": {
        "id": "ND2UOxdtZlzF"
      },
      "id": "ND2UOxdtZlzF",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kriterijum za loss\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "cATSoj3mecK8"
      },
      "id": "cATSoj3mecK8",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sa obzirom na to gde sve koristimo transform funkciju, bolje da smo je uključili u sam model\n",
        "# ipak, vreme izrade projekta je ograničeno, neka je za sad ovde\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "text_processor = Text()\n",
        "\n",
        "test_dataset = LatexDataset('/content/data/im2latex_train.csv', transform=transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,  # usually keep validation deterministic\n",
        "    num_workers=WORKERS,\n",
        "    collate_fn=lambda batch: collate_fn(batch, text_processor)\n",
        ")"
      ],
      "metadata": {
        "id": "T9nExFSQbb61"
      },
      "id": "T9nExFSQbb61",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "učitajmo prethodno sačuvani model:"
      ],
      "metadata": {
        "id": "EQMU6o3weApJ"
      },
      "id": "EQMU6o3weApJ"
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"/content/ml_image_to_latex_2024/saved_models/model9.pt\", map_location=device, weights_only=False)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-F7fvKwd_yk",
        "outputId": "2287e329-eca4-422a-fb85-0fd24072cd5f"
      },
      "id": "a-F7fvKwd_yk",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Image2LatexModel(\n",
              "  (encoder): ConvEncoder(\n",
              "    (feature_encoder): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): ReLU()\n",
              "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (6): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(520, 80)\n",
              "    (attention): Attention(\n",
              "      (decoder_attention): Linear(in_features=512, out_features=512, bias=False)\n",
              "      (encoder_attention): Linear(in_features=512, out_features=512, bias=False)\n",
              "      (attention): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (softmax): Softmax(dim=-1)\n",
              "    )\n",
              "    (concat): Linear(in_features=592, out_features=512, bias=True)\n",
              "    (rnn): LSTM(512, 512, batch_first=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (rnn2): LSTM(512, 512, batch_first=True)\n",
              "    (out): Linear(in_features=512, out_features=520, bias=True)\n",
              "    (logsoftmax): LogSoftmax(dim=-1)\n",
              "  )\n",
              "  (init_h): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (init_c): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (criterion): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, text_processor, criterion=None, log_file=None):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_bleu = 0.0\n",
        "    test_em = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images, formulas, formula_len = bind_gpu(batch)\n",
        "            formulas_in = formulas[:, :-1]\n",
        "            formulas_out = formulas[:, 1:]\n",
        "\n",
        "            # izračunajmo loss\n",
        "            with autocast():\n",
        "                outputs = model(images, formulas_in, formula_len)\n",
        "                loss = criterion(outputs.reshape(-1, outputs.shape[-1]),\n",
        "                                     formulas_out.reshape(-1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # generiši predikcije\n",
        "            predicts = model.decode_greedy_batch(images, max_length=MAX_LENGTH)\n",
        "            truths = [formula.tolist() for formula in formulas]\n",
        "\n",
        "            predict_strings = [text_processor.tokenize(text_processor.int2text(p)) for p in predicts]\n",
        "            truth_strings = [text_processor.tokenize(text_processor.int2text(t)) for t in truths]\n",
        "\n",
        "            bleu4 = corpus_bleu([[t] for t in truth_strings], predict_strings)\n",
        "            em = exact_match(predict_strings, truth_strings)\n",
        "            print(bleu4)\n",
        "            print(em)\n",
        "\n",
        "            test_bleu += bleu4\n",
        "            test_em += em\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    avg_test_bleu = test_bleu / len(test_loader)\n",
        "    avg_test_em = test_em / len(test_loader)\n",
        "\n",
        "    results = {\n",
        "        \"test_loss\": float(avg_test_loss) if avg_test_loss is not None else None,\n",
        "        \"bleu4\": float(avg_test_bleu),\n",
        "        \"em\": float(avg_test_em)\n",
        "    }\n",
        "\n",
        "    if log_file is not None:\n",
        "        with open(log_file, \"a\") as file:\n",
        "            file.write(json.dumps(results) + \"\\n\")\n",
        "\n",
        "    print(f\"Test BLEU4: {avg_test_bleu:.4f}, EM: {avg_test_em:.4f}\"\n",
        "          + (f\", Loss: {avg_test_loss:.4f}\" if avg_test_loss is not None else \"\"))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "F2pmruTdYMos"
      },
      "id": "F2pmruTdYMos",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test(model, test_loader, text_processor, criterion, log_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_ohCedKdclgT",
        "outputId": "6d4b05f7-d184-4ceb-dd01-ada70f8ddab8"
      },
      "id": "_ohCedKdclgT",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3305057844.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.31583944618279086\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.13387989978881518\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.17531312759668374\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2923333456737029\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.23527334545349146\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3194239130137035\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.21155810477248727\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.27769150495769956\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.18483250568148107\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.24586317905573393\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.24320359037040906\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2801166836246416\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.36958155105596296\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.28541420279336976\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.30763387961670574\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.19165090402806703\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3080216563620884\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.17250309543002462\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.20453990812626258\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.19665627137751723\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.228889732473468\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3152986367728963\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.25972263992640676\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.19480519598166932\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3575033264705311\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3085806224344136\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.24832964708609193\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2274507734811216\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.19765659092318505\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.23944277891298243\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.27979387988948556\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.22161422704272327\n",
            "tensor(0.0625, dtype=torch.float64)\n",
            "0.25006815479753713\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3039546500056225\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3023021117193774\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.34737731385351\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.23515138226551588\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.20109685186390766\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.22483578613564037\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2791483529100677\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2666743513710068\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2725300292651396\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.303405052806574\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2837233483613106\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2217173029073516\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.27027783345681705\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.29205355577587555\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.24351415807600824\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2098733946877093\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3040723836439287\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3365904699669935\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.18963398549535573\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3119310030191861\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.326047226665411\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2502754655124244\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.41682728783347217\n",
            "tensor(0.0625, dtype=torch.float64)\n",
            "0.2942510925868807\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2667125821667215\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.256872115280894\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2132527294131522\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.24078639144308908\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2556663514891584\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.36683346475694023\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.1966041283400302\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.22776877725856684\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.19100269954088506\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2225898979955708\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.20664101345425398\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.21156260325484538\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.34331176933637964\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2883116882098596\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2157374356162975\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.30964832219685123\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.3198003393350114\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.33926168084084585\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.22765110723133136\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2648459432124559\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.26450951851863475\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.12127149217356775\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2687805722782785\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.22976797436204371\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.2259773559604793\n",
            "tensor(0., dtype=torch.float64)\n",
            "0.29435544925300317\n",
            "tensor(0., dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3963348277.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3305057844.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, text_processor, criterion, log_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# generiši predikcije\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_greedy_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mtruths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mformula\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformulas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ml_image_to_latex_2024/image2latex.py\u001b[0m in \u001b[0;36mdecode_greedy_batch\u001b[0;34m(self, x, max_length)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ml_image_to_latex_2024/image2latex.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, encoder_out, hidden_state)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, 1, decoder_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# out: (b, 1, decoder_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, 1, n_class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}